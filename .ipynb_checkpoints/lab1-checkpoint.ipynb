{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab1 - Scikit-learn\n",
    "Author: Nikhil Naikar\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "The goal of this lab is to become familiar with the scikit-learn library.\n",
    "\n",
    "You will practice loading example datasets, perform classification and regression with linear scikit-learn models, and investigate the effects of reducing the number of features (columns in X) and the number of samples (rows in X and y).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Classification\n",
    "\n",
    "Using yellowbrick spam - classification  \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/spam.html\n",
    "\n",
    "The goal is to investigate `LogisticRegression(max_iter=2000)` and effects of reducing the number of features and number of samples on classification performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Implement convenience function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_classifier_accuracy(model, X, y):\n",
    "    '''Calculate train and validation accuracy of classifier (model)\n",
    "        \n",
    "        Splits feature matrix X and target vector y \n",
    "        with sklearn train_test_split() and random_state=956.\n",
    "        \n",
    "        model (sklearn classifier): Classifier to train and evaluate\n",
    "        X (numpy.array or pandas.DataFrame): Feature matrix\n",
    "        y (numpy.array or pandas.Series): Target vector\n",
    "        \n",
    "        returns: training accuracy, validation accuracy\n",
    "    \n",
    "    '''\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=956)\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred1 = model.predict(x_test)\n",
    "    y_pred2 = model.predict(x_train)\n",
    "    return accuracy_score(y_pred2, y_train), accuracy_score(y_pred1, y_test)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Load data\n",
    "\n",
    "Use the yellowbrick function `load_spam()`, load the spam data set into feature matrix `X` and target vector `y`.\n",
    "\n",
    "Print size and type of `X` and `y`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X:  262200\n",
      "Size of Y:  4600\n"
     ]
    }
   ],
   "source": [
    "# TODO: ADD YOUR CODE HERE\n",
    "from yellowbrick.datasets.loaders import load_spam\n",
    "X,Y = load_spam()\n",
    "print(\"Size of X: \", X.size)\n",
    "print(\"Size of Y: \", Y.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the sklearn function `train_test_split()` prepare a feature matrix `X_small` and target vector `y_small` that contain only **1%** of the rows. Use `random_state=174`.\n",
    "\n",
    "Print size and type of `X_small` and `y_small`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of x_small:  2622\n",
      "Size of y_small:  46\n"
     ]
    }
   ],
   "source": [
    "# TODO: ADD YOUR CODE HERE\n",
    "x_small, x_test, y_small, y_test = train_test_split(X, Y, train_size = 0.01, random_state=174)\n",
    "print(\"Size of x_small: \", x_small.size)\n",
    "print(\"Size of y_small: \", y_small.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Train and evaluate models\n",
    "\n",
    "1. Import `LogisticRegression` from sklearn\n",
    "2. Instantiate model `LogisticRegression(max_iter=2000)`.\n",
    "3. Create a pandas DataFrame `results` with columns: Data size, training accuracy, validation accuracy\n",
    "4. Call your convenience function `get_classifier_accuracy()` using \n",
    "    - `X` and `y`\n",
    "    - Only first two columns of `X` and `y`\n",
    "    - `X_small` and `y_small`\n",
    "5. Add the data size, training and validation accuracy for each call to the `results` DataFrame\n",
    "6. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data size</th>\n",
       "      <th>training accuracy</th>\n",
       "      <th>validation accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>262200.0</td>\n",
       "      <td>0.935072</td>\n",
       "      <td>0.918261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9200.0</td>\n",
       "      <td>0.608986</td>\n",
       "      <td>0.613043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2622.0</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Data size  training accuracy  validation accuracy\n",
       "0   262200.0           0.935072             0.918261\n",
       "1     9200.0           0.608986             0.613043\n",
       "2     2622.0           0.941176             0.750000"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: ADD YOUR CODE HERE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(max_iter=2000)\n",
    "\n",
    "results = pd.DataFrame(columns = ['Data size', 'training accuracy', 'validation accuracy'])\n",
    "train_accuracy, validation_accuracy = get_classifier_accuracy(model, X, Y) \n",
    "row = [X.size, train_accuracy, validation_accuracy]\n",
    "results.loc[len(results)] = row\n",
    "\n",
    "X_two_columns = X.iloc[:,0:2]\n",
    "train_accuracy, validation_accuracy = get_classifier_accuracy(model, X_two_columns, Y) \n",
    "row = [X_two_columns.size, train_accuracy, validation_accuracy]\n",
    "results.loc[len(results)] = row\n",
    "\n",
    "train_accuracy, validation_accuracy = get_classifier_accuracy(model, x_small, y_small)\n",
    "row = [x_small.size, train_accuracy, validation_accuracy]\n",
    "results.loc[len(results)] = row\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Questions\n",
    "1. What is the validation accuracy using all data? What is the difference between training and validation accuracy?\n",
    "1. How does the validation accuracy and difference between training and validation change when only two columns are used? Provide values.\n",
    "1. How does the validation accuracy and difference between training and validation change when only 1% of the rows are used? Provide values.\n",
    "\n",
    "*YOUR ANSWERS HERE*\n",
    "1. The validation accuracy is 91% when using all the data. There is a 2% difference between the training and validation accuracies.\n",
    "1. The validation accuracy got worse and decreased by 30% (91% to 61%) when only using two columns when compared to using all the data. The difference now between training and validation is about 1% which is a 1% decrease from when all the data was being used.\n",
    "1. The validation accuracy improved and increased by 14% (61% to 75%) when only using 1% of the rows when compared to using two columns. Also, the validation accuracy is worse and decreased by 8% (91% to 83%) when compared to using all the data. The difference now between training and validation is about about 19%, 18% increase from when only using two columns were used and 17% increase when using all the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Regression\n",
    "\n",
    "Using yellowbrick energy - regression  \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/energy.html\n",
    "\n",
    "The goal is to investigate `LinearRegression()` and effects of reducing the number of features and number of samples on regression performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Implement convenience function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_regressor_mse(model, X, y):\n",
    "    '''Calculate train and validation mean-squared error (mse) of regressor (model)\n",
    "        \n",
    "        Splits feature matrix X and target vector y \n",
    "        with sklearn train_test_split() and random_state=956.\n",
    "        \n",
    "        model (sklearn regressor): Regressor to train and evaluate\n",
    "        X (numpy.array or pandas.DataFrame): Feature matrix\n",
    "        y (numpy.array or pandas.Series): Target vector\n",
    "        \n",
    "        returns: training mse, validation mse\n",
    "    \n",
    "    '''\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=956)\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred1 = model.predict(x_test)\n",
    "    y_pred2 = model.predict(x_train)\n",
    "    return mean_squared_error(y_pred2, y_train), mean_squared_error(y_pred1, y_test)\n",
    "   \n",
    "    #TODO: IMPLEMENT FUNCTION BODY\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Load data\n",
    "\n",
    "Use the yellowbrick function `load_energy()` load the energy data set into feature matrix `X` and target vector `y`.\n",
    "\n",
    "Print dimensions and type of `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of X:  (768, 8)\n",
      "Dimensions of Y:  (768,)\n"
     ]
    }
   ],
   "source": [
    "# TODO: ADD YOUR CODE HERE\n",
    "from yellowbrick.datasets.loaders import load_energy\n",
    "X,Y = load_energy()\n",
    "print(\"Dimensions of X: \", X.shape)\n",
    "print(\"Dimensions of Y: \", Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the sklearn function `train_test_split()` prepare a feature matrix `X_small` and target vector `y_small` that contain only **1%** of the rows. Use `random_state=174`.\n",
    "\n",
    "Print size and type of `X_small` and `y_small`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of x_small:  56\n",
      "Size of y_small:  7\n"
     ]
    }
   ],
   "source": [
    "# TODO: ADD YOUR CODE HERE\n",
    "x_small, x_test, y_small, y_test = train_test_split(X, Y, train_size = 0.01, random_state=174)\n",
    "print(\"Size of x_small: \", x_small.size)\n",
    "print(\"Size of y_small: \", y_small.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Train and evaluate models\n",
    "\n",
    "1. Import `LinearRegression` from sklearn\n",
    "2. Instantiate model `LinearRegression()`.\n",
    "3. Create a pandas DataFrame `results` with columns: Data size, training MSE, validation MSE\n",
    "4. Call your convenience function `get_regressor_mse()` using \n",
    "    - `X` and `y`\n",
    "    - Only first two columns of `X` and `y`\n",
    "    - `X_small` and `y_small`\n",
    "5. Add the data size, training and validation MSE for each call to the `results` DataFrame\n",
    "6. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data size</th>\n",
       "      <th>training MSE</th>\n",
       "      <th>validation MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6144.0</td>\n",
       "      <td>7.978156e+00</td>\n",
       "      <td>10.315308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1536.0</td>\n",
       "      <td>5.360043e+01</td>\n",
       "      <td>46.410426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56.0</td>\n",
       "      <td>3.092335e-28</td>\n",
       "      <td>69.977449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Data size  training MSE  validation MSE\n",
       "0     6144.0  7.978156e+00       10.315308\n",
       "1     1536.0  5.360043e+01       46.410426\n",
       "2       56.0  3.092335e-28       69.977449"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: ADD YOUR CODE HERE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "results = pd.DataFrame(columns = ['Data size', 'training MSE', 'validation MSE'])\n",
    "train_accuracy, validation_accuracy = get_regressor_mse(model, X, Y) \n",
    "row = [X.size, train_accuracy, validation_accuracy]\n",
    "results.loc[len(results)] = row\n",
    "\n",
    "X_two_columns = X.iloc[:,0:2]\n",
    "train_accuracy, validation_accuracy = get_regressor_mse(model, X_two_columns, Y) \n",
    "row = [X_two_columns.size, train_accuracy, validation_accuracy]\n",
    "results.loc[len(results)] = row\n",
    "\n",
    "train_accuracy, validation_accuracy = get_regressor_mse(model, x_small, y_small)\n",
    "row = [x_small.size, train_accuracy, validation_accuracy]\n",
    "results.loc[len(results)] = row\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Questions\n",
    "1. What is the validation MSE using all data? What is the difference between training and validation MSE?\n",
    "1. How does the validation MSE and difference between training and validation change when only two columns are used? Provide values.\n",
    "1. How does the validation MSE and difference between training and validation change when only 1% of the rows are used? Provide values.\n",
    "\n",
    "*YOUR ANSWERS HERE*\n",
    "1. Validation MSE using all data is 10. Difference between training and validation MSE is about 2.\n",
    "1. Validation MSE using only two columns got worse and increased to 46, increased by 36 (10 to 46) when compared to using only two columns. Difference between training and validation MSE is about 8, difference increased by 6 (2 to 8) when compared to using only two columns.\n",
    "1. Validation MSE using only 1% of the rows got worse and is about 70, increased by 24 (46 to 70) when compared to using two columns. Also, the validation accuracy is worse than when all of the data was used (10 to 70, increased by 60). The difference now between training and validation is about 70, which is bigger than the difference when the all the data was used (2 to 70, increased by 68) and when only two columns was used (8 to 70, increased by 62)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Observations/Interpretation\n",
    "\n",
    "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
    "\n",
    "(case 1 = when all the data is used, case 2 = when only two columns were used, case 3 = 1% of the rows were used)<br>\n",
    "\n",
    "I noticed for classification:<br>\n",
    "-For case 1, the training accuracy (93%) and validation accuracy (91%) were really high<br>\n",
    "-For case 2, the training accuracy (61%) and validation accuracy (61%) were really low<br>\n",
    "-For case 3, the training accuracy (94%) was high and validation accuracy (75%) was low<br>\n",
    "The validation accuracy was the biggest when all the data was used and the training accuracy was the biggest when 1% of the rows were used.<br>\n",
    "\n",
    "I noticed for regression:<br>\n",
    "-For case 1, the training MSE (8) and validation MSE (10) were good<br>\n",
    "-For case 2, the training MSE (54) and validation MSE (46) were bad<br>\n",
    "-For case 3, the training MSE (basically 0, a really small number) was amazing and validation MSE (70) was very bad<br>\n",
    "The validation MSE was the best when all the data was used and the training MSE was the biggest when 1% of the rows were used.<br>\n",
    "\n",
    "In the lectures, it was stated that linear models work quite well with large datasets, this point is definitely proven since the best overall outcome for both classification and regression came from case 1. It was also stated in the lectures that the linear models often performs well when the number of features is large compared to number of samples. It makes sense now why case 2 was the overall worse for both classification and regression because the features was only two. It also makes sense why the training accuracy and MSE in case 3 were the best. However, in case 3 the validation accuracy and MSE were not the best, maybe this is becasue 1% of rows is way to little."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Reflection\n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challangeing, motivating\n",
    "while working on this assignment.\n",
    "\n",
    "\n",
    "*ADD YOUR THOUGHTS HERE*<br>\n",
    "I like how this assignment was strutured with easy to understand descrptions of what to do. I do appreciate the questions asked as well.\n",
    "It was interesting to see how manipulating of the data size affected the training and testing values."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
